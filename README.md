#mcp-gnns-fedcsis


# run server

```python
nohup python mcp-gnns-server.py > log.log &
``` 

lub  w osobnym terminalu.

# run client

```python
python mcp-gnns-client.py
```

komedy do użycia pojawią sie po uruchomieniu klienta `mcp-gnns-client.py`


# pull llama3.2

- install ollama
- ollama pull llama3.2
